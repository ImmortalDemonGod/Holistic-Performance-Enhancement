
(done J)fix training from checkpoint

fix the evaluate to utilize evaluation data in its proper form (only use eval_data_prep for data)

fix the finetuning to utilize evaluation data in its proper form (only use eval_data_prep for data)
implement custom finetuning dropout values (if you just make these like 1.75* bigger than what the model was trained on it should be more effective than the norm)

grokfast

integrate a Combined Dice Loss and Hard Example Mining Loss into the existing cross entropy loss

im also pretty sure config file is an absolute mess but im not sure i care
