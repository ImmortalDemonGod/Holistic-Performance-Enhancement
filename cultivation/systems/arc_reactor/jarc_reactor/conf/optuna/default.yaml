# Default Optuna configuration

n_trials: 1
study_name: "jarc_optimization_v3"
storage_url: "sqlite:///jarc_optuna.db"

param_ranges:
  # Model Architecture Parameters
  d_model: [32, 2048, 16]      # Original: (32, 2048, 16) -> Hydra typically uses lists for ranges or choices
  heads: [2, 4, 8, 16, 32, 64]
  encoder_layers: [1, 12]     # Original: (1, 12)
  decoder_layers: [1, 12]     # Original: (1, 12)
  d_ff: [64, 2048, 64]        # Original: (64, 2048, 64)
  dropout: [0.01, 0.7]        # Original: (0.01, 0.7)

  # Context Encoder Parameters
  context_encoder_d_model: [32, 512, 32] # Original: (32, 512, 32)
  context_encoder_heads: [2, 4, 8]

  # Training Parameters
  batch_size: [8, 512]                   # Original: (8, 512)
  learning_rate: [0.000001, 0.1]            # Original: (1e-6, 1e-1)
  max_epochs: [4, 5, 1]                  # Original: (4, 5, 1)
  gradient_clip_val: [0.0, 5.0]          # Original: (0.0, 5.0)

pruning:
  n_warmup_steps: 5
  n_startup_trials: 10
  patience: 20
  pruning_percentile: 25
