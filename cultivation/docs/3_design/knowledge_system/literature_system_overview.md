
# ğŸ“šÂ Literature Pipeline &Â DocInsightÂ Integration  
*Turning scattered preâ€‘prints into structured insight, metrics, and action for the **Cultivation** programme.*

---

## 0Â Â·Â ReadingÂ Map

| Section | Why read it? | If you need moreâ€¦ |
|---------|--------------|-------------------|
| **Â§Â 1Â VisionÂ & Goals** | What weâ€™re building and how weâ€™ll know it works | RoadmapÂ â†’Â `docs/3_design/architecture_overview.md` |
| **Â§Â 2Â Context (C4Â Lâ€‘1)** | How ETLâ€‘B slots into the whole system & fallback story | Highâ€‘level C4Â â†’Â same file Â§Â 1 |
| **Â§Â 3Â Folder Layout** | Where code/data live & naming rules | â€”
| **Â§Â 4Â Component Catalogue** | Whoâ€‘doesâ€‘what across P0â€‘P2 | Links to code stubs |
| **Â§Â 5Â Interfaces & API Contracts** | Exact JSON for DocInsight HTTP callsÂ +Â note skeleton | DocInsight vendored docs |
| **Â§Â 6Â DataÂ Schemas** | Paper metadata, reading stats, LanceDB handling | `schemas/` dir |
| **Â§Â 7Â Process Flow (P0â€‘P2)** | Sequence diagrams & fallback branches | â€”
| **Â§Â 8Â Synergy/Potential Hooks** | Equations & metric wiring into Î  | `potential_overview.md` |
| **Â§Â 9Â Testing** | Layered test plan & mocking patterns | `tests/literature/` |
| **Â§Â 10Â CI/CD** | GitHub Action snippets & Docker image | `.github/workflows/` |
| **Â§Â 11Â Roadmap & ADRs** | Open decisions + deadlines | `docs/3_design/adr/` |
| **Â§Â 12Â Glossary** | Projectâ€‘specific jargon | â€”

LegendÂ Â·Â **P0**Â = baselineâ€ƒ**P1**Â = automationâ€ƒ**P2**Â = metrics couplingâ€ƒPâ‰¥3Â = stretch.

---

## 1Â Â·Â Vision & Measurable Goals

| ID | Goal | Phase | â€œDoneâ€ Definition |
|----|------|-------|-------------------|
| **LITâ€‘01** | *Oneâ€‘command ingest* of an arXiv URL/ID | P0 | `pdf/2404.12345.pdf`Â +Â `metadata/2404.12345.json` exist |
| **LITâ€‘02** | *Semantic search & summary* across all curated papers | P0 | `lit-search "logistic"` returns answer with `relevance_scoreÂ â‰¥Â 0.60` |
| **LITâ€‘03** | *Nightly* preâ€‘print fetch for tags `ml, rna, arc` | P1 | GitHub Action commit/PR with â‰¥1 new PDF when available |
| **LITâ€‘04** | TaskÂ Master surfaces *one unread* paper daily | P1 | Automation issue created, task visible in TM CLI |
| **LITâ€‘05** | Reading metrics feed **C(t)** in Potential Î  | P2 | `reading_stats.parquet` consumed by `potential_engine.py` |

---

## 2Â Â·Â System ContextÂ (C4Â LevelÂ 1)

```mermaid
flowchart TD
    subgraph Cultivation
        direction LR
        ETL_R[ETL_R<br/>(Running)]
        ETL_S[ETL_S<br/>(Commits)]
        ETL_B[[**ETL_B**<br/>(Literature)]]
        SY[calculate_synergy.py]
        PE[potential_engine.py]
        SCHED[optimize_time.py]
        DS[(DataÂ Store<br/>CSV/Parquet)]
    end

    ETL_R --> SY
    ETL_S --> SY
    ETL_B -->|C(t)| SY
    SY --> PE
    PE --> SCHED
    ETL_B --> DS

    subgraph DocInsightÂ Service
        DI_API(HTTPÂ API)<br/>\n`/start_research`\n`/get_results`
        DI_DB[(LanceDB index)]
    end

    ETL_B <..>|search/summarise| DI_API
    classDef opt stroke-dasharray:5,5
    DI_API:::opt
```

*FallbackÂ behaviour*Â â€” if `DI_API` is unreachable, ETLâ€‘B logs a warning and completes ingest without search/summary; downstream metrics default `novel_vectorsÂ =Â 0`.

---

## 3Â Â·Â Folder & Naming Conventions

```
cultivation/
â”œâ”€ literature/
â”‚  â”œâ”€ pdf/                 # raw PDFs (PKÂ = arXivÂ ID)
â”‚  â”œâ”€ metadata/            # 2404.12345.json
â”‚  â”œâ”€ notes/               # 2404.12345.md
â”‚  â”œâ”€ cards/               # spacedâ€‘repetition export
â”‚  â””â”€ .gitignore           # excludes *.pdf, LanceDB artefacts
â”œâ”€ scripts/
â”‚  â””â”€ literature/
â”‚     â”œâ”€ fetch_paper.py          # ingest single paper (P0)
â”‚     â”œâ”€ docinsight_client.py    # async HTTP client (P0)
â”‚     â”œâ”€ fetch_arxiv_batch.py    # nightly batch (P1)
â”‚     â””â”€ metrics_literature.py   # produce reading_stats (P2)
â”œâ”€ third_party/
â”‚  â””â”€ docinsight/          # vendored, Git submodule @ commitÂ abc123
â””â”€ schemas/                # JSONâ€‘Schema & Greatâ€‘Expectations
```

*DocInsight* stores its **LanceDB** index under `third_party/docinsight/.cache/`; path is `.gitignored` and rebuilt in CI from PDFs.

---

## 4Â Â·Â Component Catalogue

| Name | Phase | Responsibility | Inputs | Outputs |
|------|-------|----------------|--------|---------|
| **fetch_paper.py** | P0 | â€¢ Download PDF/metadata<br>â€¢ Create note skeleton<br>â€¢ Kick DocInsight indexing & abstract summary | arXiv URL/ID | PDF â€¢ JSON â€¢ MD note |
| **docinsight_client.py** | P0 | Thin wrapper: <br>`start(query)` â†’Â job_idÂ â€¢Â `poll(job_id)` | Query string | JSON (`answer`,`score`,Â `chunks`) |
| **lit-search CLI** | P0 | Userâ€‘facing search: wraps client | Query | Markdown answer |
| **fetch_arxiv_batch.py** | P1 | Scheduled tagâ€‘based fetch (cron) | tag list | Multiple PDFs/JSON |
| **metrics_literature.py** | P2 | Parse notes & TaskMaster logs â†’ weekly stats | notes/, TM DB | `reading_stats.parquet` |
| **DocInsightÂ Service** | P0â€‘P2 | RAG pipeline, semantic index | `literature/pdf/` dir | LanceDB â€¢ HTTP answers |

---

## 5Â Â·Â Interfaces & APIÂ Contracts

### 5.1Â DocInsight HTTP

| Endpoint | Method | RequestÂ (body) | Response |
|----------|--------|---------------|----------|
| `/start_research` | POST | `{ "query": "string", "force_index": ["2404.12345.pdf"]? }` | `{ "job_id": "uuid" }` |
| `/get_results` | POST | `{ "job_ids": ["uuid", ...] }` | `[ { "job_id": "...", "status": "done|pending|error", "answer": "markdown", "relevance": 0.87, "novelty": 0.34, "chunks": [...] } ]` |

*`novelty`* = cosine distance of answerâ€‘supporting chunk embeddings vs. 6â€‘week moving average corpus centroid (0Â =Â old, 1Â =Â fully novel).

### 5.2Â Note Skeleton (`notes/{id}.md`)

```markdown
# {{ title }}
*ArXiv {{ id }} Â· {{ year }}*

> **AbstractÂ (autofilled):**  
> {{ abstract }}

## TL;DR  <!-- mark complete when filled -->
- [ ]

## Key Points
- [ ]

## Relevance to Cultivation
- [ ]

## TODOs
- [ ] implement ___ in `scripts/`
```

---

## 6Â Â·Â Data Schemas

### 6.1Â PaperÂ MetadataÂ (`metadata/*.json`)

```jsonc
{
  "id": "2404.12345",
  "title": "Synergy in Logistic Growth Models",
  "authors": ["A. Euler", "L. Verhulst"],
  "year": 2024,
  "tags": ["ml", "rna"],
  "abstract": "...",
  "code_links": ["https://github.com/euler/logistic"],
  "imported_at": "2025-04-18T10:03:00Z"
}
```

*Validated in CI viaÂ `schemas/paper.schema.json` + GreatÂ Expectations (fromÂ P1).*

### 6.2Â ReadingÂ StatsÂ (`reading_stats.parquet`)

| col | type | description |
|-----|------|-------------|
| `iso_week` | date | Monday of ISOâ€‘week |
| `papers_read` | int | notes with `TL;DR` âœ”ï¸ |
| `minutes_spent` | int | Sum TaskMaster *actual* minutes |
| `avg_novelty` | float | Mean of `novelty` scores for that week (0â€‘1) |

---

## 7Â Â·Â Process Flow

### 7.1Â P0Â â€”Â Single Ingest & Search

```mermaid
sequenceDiagram
    autonumber
    participant Dev
    participant FP as fetch_paper.py
    participant FS as FileStore
    participant DI as DocInsight API
    participant NC as Note
    Dev->>FP: fetch_paper 2404.12345
    FP->>FS: save PDF + metadata
    FP->>DI: /start_research {query: "abstract of 2404.12345", force_index:[pdf]}
    DI-->>FP: {job_id}
    loop poll
        FP->>DI: /get_results {job_id}
        alt done
            DI-->>FP: answer + novelty
        else pending
            FP-->>Dev: spinner
        end
    end
    FP->>NC: write note (abstract, placeholder TL;DR)
    FP-->>Dev: "Paper ingested âœ“"
```

*If `/start_research` fails â†’ skip DI steps, write note skeleton, mark `noveltyÂ =Â 0`.*

### 7.2Â P1Â â€”Â Nightly Batch  
*See `ci-literature.yml`; essentially a loop over IDs + optional `force_index` batch call.*

### 7.3Â P2Â â€”Â Metrics

```mermaid
flowchart LR
    TM[TaskMaster DB] --> ML(metrics_literature.py)
    NC[notes/*.md] --> ML
    ML --> RS[reading_stats.parquet] --> PE
```

---

## 8Â Â·Â Synergy & Potential Integration

\[EquationÂ 1Â â€” cognitive channel\]

\[
C(t)=\alpha_1\frac{\text{papers\_read}}{\max_{6w}}+
     \alpha_2\frac{\text{minutes\_spent}}{\max_{6w}}+
     \alpha_3\,\text{avg\_novelty}
\]

*Weights* \(\alpha_i\) updated monthly via ridge regression (see **ADRâ€‘03Â Potentialâ€‘Weights**).  
`avg_novelty` gracefully degrades toÂ 0 when DocInsight is offline.

---

## 9Â Â·Â Testing Strategy

| Layer | Example | Tool | Phase |
|-------|---------|------|-------|
| **Unit** | `fetch_paper` saves valid JSON (network mocked) | `pytest`, `responses` | P0 |
| **Contract** | Mock DI serverÂ â†’Â `lit-search` returns `relevanceâ‰¥0.6` | `pytest` + `aiohttp` fixture | P0 |
| **Schema** | `metadata/*.json` vs. JSONâ€‘Schema | GreatÂ Expectations | P1 |
| **Integration** | Batch fetch â†’ metrics pipeline yields weekly row | `pytest` | P2 |
| **E2E** | GH Action runs `lit-search "logistic"` smoke test | GitHubÂ Actions | P0 |

Mock server script: `tests/mocks/docinsight_mock.py` implements same endpoints.

---

## 10Â Â·Â CIÂ /Â CD

### 10.1Â Docker Image (optional local dev)

```
docker build -f docker/Dockerfile.docinsight -t cultivation/docinsight:0.4 .
docker compose -f docker/docker-compose.yml up -d docinsight
```

### 10.2Â GitHub ActionÂ `ci-literature.yml`

```yaml
name: literature-nightly
on:
  schedule: [{cron: '0 6 * * 1'}]  # Monday 06:00Â UTC
jobs:
  batch-fetch:
    runs-on: ubuntu-latest
    env:
      DOCINSIGHT_URL: http://localhost:8000
    services:
      docinsight:
        image: cultivation/docinsight:0.4
        ports: ['8000:8000']
    steps:
      - uses: actions/checkout@v4
      - run: pip install -r requirements.txt
      - run: python scripts/literature/fetch_arxiv_batch.py --tags ml rna arc
      - run: python scripts/literature/docinsight_client.py reindex literature/pdf
      - name: Commit new PDFs & metadata
        run: |
          git config --local user.name 'github-actions'
          git config --local user.email 'actions@github.com'
          git add literature/pdf/*.pdf literature/metadata/*.json || true
          git diff --staged --quiet || \
            git commit -m "ci: weekly arXiv ingest" && git push
```

*(Action opens a PR if `push` rights are restricted in main branch protection.)*

---

## 11Â Â·Â RoadmapÂ &Â OpenÂ Decisions

| ID | Question | Target ADR | Needed by |
|----|----------|------------|-----------|
| **Qâ€‘LITâ€‘01** | Vendored submodule vs. GHCR Docker for DocInsight | ADRâ€‘05 | P0 |
| **Qâ€‘LITâ€‘02** | Disable Sciâ€‘Hub (`scidownl`) by default? | ADRâ€‘06 | P0 |
| **Qâ€‘LITâ€‘03** | Store LanceDB indexÂ in repo artifactsÂ vs. rebuild in CI | ADRâ€‘07 | P1 |
| **Qâ€‘LITâ€‘04** | Obsidian vault sync for notes? | ADRâ€‘08 | P2 |

---

## 12Â Â·Â Glossary

| Term | Definition |
|------|------------|
| **DocInsight** | Vendored RAG microâ€‘service supplying semantic search, novelty & summaries. |
| **ETLâ€‘B** | Cultivationâ€™s literature Extractâ€‘Transformâ€‘Load pipeline (this subsystem). |
| **LanceDB** | Columnar vector store used by DocInsight for embedding search. |
| **novelty** | Cosine distance (0â€‘1) between retrieved chunk embeddings and 6â€‘week corpus centroid. |
| **TaskÂ Master** | Personal taskâ€‘queue tool used across Cultivation (cf. `task_master_integration.md`). |
| **Î  (Potential)** | Multiâ€‘channel potential function capturing GrowthÂ Capacity (see background docs). |
| **Î”BÂ pred** | Synergy baseline prediction model (SARIMA / moving average). |

---

### âœ¨Â Outcome

* **P0** â†’ reproducible singleâ€‘paper ingest & repoâ€‘local semantic search.  
* **P1** â†’ automated corpus growth + daily reading nudges.  
* **P2** â†’ closed feedback loop: cognitive effort metrics flow into Synergy & Potential.

This document unifies conceptual clarity, concrete file paths, exact API contracts, robust testing, and CI automationâ€”**greater than the sum of its parts** and ready for immediate implementation.
